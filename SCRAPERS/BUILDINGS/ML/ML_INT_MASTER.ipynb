{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "from datetime import datetime\n",
    "from ML.tools import savedata as sd\n",
    "from ML.directories import master_directory as md\n",
    "\n",
    "#Visual de data (permite ver todo un df)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ENVIRONMENT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "\n",
    "web = 'ML'\n",
    "mth = 'FEB'       #Update each month\n",
    "yr = '2024'       #Update each month\n",
    "\n",
    "#Master directory\n",
    "master_dir = md()\n",
    "master_dir = f'{master_dir}/{web}'\n",
    "\n",
    "\n",
    "#EXPORT\n",
    "#Directories to export files \n",
    "result_dir = f'{master_dir}/INTERNAL/JOIN'\n",
    "monitoring_dir = f'{master_dir}/INTERNAL/MONITORING/{yr}/{mth}'\n",
    "\n",
    "#Export files \n",
    "###############################################################################################################\n",
    "fl_master = f'{web}_{mth}{yr}_INT'\n",
    "\n",
    "\n",
    "# Ruta al archivo .bat\n",
    "ruta_bat = r'C:/Users/luisG/GIT/SCRAPING/deltemporal_exect.bat'\n",
    "ruta_txt = r'C:Users/luisG/AppData/Local/Temp/eliminacion_log.txt'  #Is could change depending the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read RENT df'S "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6361\n",
      "6361\n"
     ]
    }
   ],
   "source": [
    "op = 'Rental'\n",
    "fl_pre = f'{web}_join_{op}INT_{mth}{yr}_'\n",
    "# Obtén la lista de nombres de archivo CSV en la carpeta\n",
    "archivos_csv = [archivo for archivo in os.listdir(result_dir) if archivo.endswith('.csv') and archivo.startswith(fl_pre)]\n",
    "\n",
    "# Inicializa una lista para almacenar los DataFrames cargados desde los archivos CSV\n",
    "dataframes = []\n",
    "\n",
    "# Carga cada archivo CSV en un DataFrame y agrega a la lista\n",
    "for archivo in archivos_csv:\n",
    "    ruta_completa = os.path.join(result_dir, archivo)\n",
    "    df = pd.read_csv(ruta_completa, sep=';', encoding='utf-16')\n",
    "    dataframes.append(df)\n",
    "    \n",
    "\n",
    "# Combina los DataFrames en uno solo\n",
    "rental = pd.concat(dataframes, ignore_index=True)\n",
    "print(len(rental))\n",
    "\n",
    "#Drop_duplicates\n",
    "rental = rental.drop_duplicates(subset=['Codigo'])\n",
    "print(len(rental))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SALE df'S "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56919\n",
      "56919\n"
     ]
    }
   ],
   "source": [
    "op = 'Sale'\n",
    "fl_pre = f'{web}_join_{op}INT_{mth}{yr}_'\n",
    "# Obtén la lista de nombres de archivo CSV en la carpeta\n",
    "archivos_csv = [archivo for archivo in os.listdir(result_dir) if archivo.endswith('.csv') and archivo.startswith(fl_pre)]\n",
    "\n",
    "# Inicializa una lista para almacenar los DataFrames cargados desde los archivos CSV\n",
    "dataframes = []\n",
    "\n",
    "# Carga cada archivo CSV en un DataFrame y agrega a la lista\n",
    "for archivo in archivos_csv:\n",
    "    ruta_completa = os.path.join(result_dir, archivo)\n",
    "    df = pd.read_csv(ruta_completa, sep=';', encoding='utf-16')\n",
    "    dataframes.append(df)\n",
    "    \n",
    "\n",
    "# Combina los DataFrames en uno solo\n",
    "sale = pd.concat(dataframes, ignore_index=True)\n",
    "print(len(sale))\n",
    "\n",
    "#Drop_duplicates\n",
    "sale = sale.drop_duplicates(subset=['Codigo'])\n",
    "print(len(sale))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63280\n"
     ]
    }
   ],
   "source": [
    "exportable = pd.concat([rental, sale], ignore_index=True)\n",
    "print(len(exportable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(exportable, f'{monitoring_dir}/{fl_master}')\n",
    "exportable.to_excel(f'{monitoring_dir}/{fl_master}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
