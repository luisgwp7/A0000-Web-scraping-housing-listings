{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import datetime\n",
    "from FR.frontpage import scrapeFrontPage, regexFrontData\n",
    "from FR.generate_url import returnUrlHousingtoScrap \n",
    "from FR.tools import savedata as sd\n",
    "from FR.directories import master_directory\n",
    "#Visual de data (permite ver todo un df)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ENVIRONMENT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "month = 'FEB'       #Update each month\n",
    "year = '2024'         #Update if the year changes\n",
    "\n",
    "# Constants  \n",
    "OPERATION = 'Sale'\n",
    "WEB = 'FR'\n",
    "\n",
    "#Master directory\n",
    "master_dir = master_directory()\n",
    "master_dir = f'{master_dir}/{WEB}'\n",
    "\n",
    "\n",
    "#Directories to export files \n",
    "result_dir = f'{master_dir}/FRONTPAGE/JOIN'\n",
    "monitoring_dir = f'{master_dir}/FRONTPAGE/MONITORING/{year}/{month}'\n",
    "\n",
    "#Export files \n",
    "###############################################################################################################\n",
    "#This files are going to be joined for create the master file, which contains all the data for the fron page\n",
    "fl_pre = f'{WEB}_join_{OPERATION}_{month}{year}_'\n",
    "\n",
    "fl_master = f'{WEB}_{month}{year}_{OPERATION}_Front'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlaces generados: 370\n"
     ]
    }
   ],
   "source": [
    "df_enlaces = returnUrlHousingtoScrap('Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se crearon 16 DataFrames para df_enlaces:\n",
      "FR_join_Sale_FEB2024_0\n",
      "FR_join_Sale_FEB2024_24\n",
      "FR_join_Sale_FEB2024_48\n",
      "FR_join_Sale_FEB2024_72\n",
      "FR_join_Sale_FEB2024_96\n",
      "FR_join_Sale_FEB2024_120\n",
      "FR_join_Sale_FEB2024_144\n",
      "FR_join_Sale_FEB2024_168\n",
      "FR_join_Sale_FEB2024_192\n",
      "FR_join_Sale_FEB2024_216\n",
      "FR_join_Sale_FEB2024_240\n",
      "FR_join_Sale_FEB2024_264\n",
      "FR_join_Sale_FEB2024_288\n",
      "FR_join_Sale_FEB2024_312\n",
      "FR_join_Sale_FEB2024_336\n",
      "FR_join_Sale_FEB2024_360\n"
     ]
    }
   ],
   "source": [
    "# Divide the df in 24 observations for don't be catch in the scraping \n",
    "num_dfs = len(df_enlaces) // 24 + (1 if len(df_enlaces) % 24 != 0 else 0)\n",
    "\n",
    "dfs = {f'{fl_pre}{i}': df_enlaces.iloc[i:i+24] for i in range(0, len(df_enlaces), 24)}\n",
    "\n",
    "print(f'You have created {num_dfs} DataFrames from df_enlaces:')\n",
    "for key in dfs:\n",
    "    print(f'{key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Scraping__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El proceso de scraping ha comenzado a las 07:48 del 01/02/2024\n",
      "Realizando scraping en FR_join_Sale_FEB2024_0\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_0.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_24\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_24.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_48\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_48.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_72\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_72.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_96\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_96.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_120\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_120.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_144\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_144.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_168\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_168.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_192\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_192.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_216\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_216.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_240\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_240.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_264\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_264.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_288\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_288.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_312\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Scraping completado para FR_join_Sale_FEB2024_312.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_336\n",
      "Enlace 1 de 24\n",
      "Enlace 2 de 24\n",
      "Enlace 3 de 24\n",
      "Enlace 4 de 24\n",
      "Enlace 5 de 24\n",
      "Enlace 6 de 24\n",
      "Enlace 7 de 24\n",
      "Enlace 8 de 24\n",
      "Enlace 9 de 24\n",
      "Enlace 10 de 24\n",
      "Enlace 11 de 24\n",
      "Enlace 12 de 24\n",
      "Enlace 13 de 24\n",
      "Enlace 14 de 24\n",
      "Enlace 15 de 24\n",
      "Enlace 16 de 24\n",
      "Enlace 17 de 24\n",
      "Enlace 18 de 24\n",
      "Enlace 19 de 24\n",
      "Enlace 20 de 24\n",
      "Enlace 21 de 24\n",
      "Enlace 22 de 24\n",
      "Enlace 23 de 24\n",
      "Enlace 24 de 24\n",
      "Error al procesar la p√°gina 1: Message: stale element reference: stale element not found\n",
      "  (Session info: headless chrome=120.0.6099.217); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6E39B82B2+55298]\n",
      "\t(No symbol) [0x00007FF6E3925E02]\n",
      "\t(No symbol) [0x00007FF6E37E05AB]\n",
      "\t(No symbol) [0x00007FF6E37E509C]\n",
      "\t(No symbol) [0x00007FF6E37E732A]\n",
      "\t(No symbol) [0x00007FF6E385B12B]\n",
      "\t(No symbol) [0x00007FF6E38420AA]\n",
      "\t(No symbol) [0x00007FF6E385AAA4]\n",
      "\t(No symbol) [0x00007FF6E3841E83]\n",
      "\t(No symbol) [0x00007FF6E381670A]\n",
      "\t(No symbol) [0x00007FF6E3817964]\n",
      "\tGetHandleVerifier [0x00007FF6E3D30AAB+3694587]\n",
      "\tGetHandleVerifier [0x00007FF6E3D8728E+4048862]\n",
      "\tGetHandleVerifier [0x00007FF6E3D7F173+4015811]\n",
      "\tGetHandleVerifier [0x00007FF6E3A547D6+695590]\n",
      "\t(No symbol) [0x00007FF6E3930CE8]\n",
      "\t(No symbol) [0x00007FF6E392CF34]\n",
      "\t(No symbol) [0x00007FF6E392D062]\n",
      "\t(No symbol) [0x00007FF6E391D3A3]\n",
      "\tBaseThreadInitThunk [0x00007FFD6035257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFD618EAA58+40]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completado para FR_join_Sale_FEB2024_336.\n",
      "--------------------------------------------------\n",
      "Realizando scraping en FR_join_Sale_FEB2024_360\n",
      "Enlace 1 de 10\n",
      "Enlace 2 de 10\n",
      "Enlace 3 de 10\n",
      "Enlace 4 de 10\n",
      "Enlace 5 de 10\n",
      "Enlace 6 de 10\n",
      "Enlace 7 de 10\n",
      "Enlace 8 de 10\n",
      "Enlace 9 de 10\n",
      "Enlace 10 de 10\n",
      "Scraping completado para FR_join_Sale_FEB2024_360.\n",
      "--------------------------------------------------\n",
      "El proceso de scraping ha terminado a las 16:08 del 01/02/2024\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(f\"The process began at {start_time.strftime('%H:%M')} of {start_time.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    for df_key, df_value in dfs.items():\n",
    "        print(f\"Scraping of {df_key}\")\n",
    "        global resultado_df\n",
    "        # Create en empty df \n",
    "        resultado_df = pd.DataFrame()\n",
    "        contador_actual = 0\n",
    "        # Create a list for storage the results of each url \n",
    "        resultados = []\n",
    "        # Iterate between the list of urls \n",
    "        for index, row in df_value.iterrows():\n",
    "            contador_actual += 1\n",
    "            print(f\"Enlace {contador_actual} de {len(df_value)}\")\n",
    "            \n",
    "            link = row[\"Enlace\"]\n",
    "            df_resultado = scrapeFrontPage(link) \n",
    "            resultados.append(df_resultado)\n",
    "\n",
    "        # Join the results in a df \n",
    "        resultado_df = pd.concat(resultados, ignore_index=True)\n",
    "        \n",
    "        # Save the data in the directory of results\n",
    "        sd(resultado_df, f'{result_dir}/{df_key}')\n",
    "\n",
    "        print(f\"Scraping completado para {df_key}.\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    # End the scraping: \n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"The process have ended at {end_time.strftime('%H:%M')} of {end_time.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Se produjo un error en el scraping: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251365\n"
     ]
    }
   ],
   "source": [
    "# Obtain the list of names of files you saved in the result diectory\n",
    "# This is going to take into account the name of each file \n",
    "archivos_csv = [archivo for archivo in os.listdir(result_dir) if \n",
    "                archivo.endswith('.csv') and archivo.startswith(fl_pre)]\n",
    "\n",
    "# Save the dataframes in this empty list \n",
    "dataframes = []\n",
    "\n",
    "# Reading each CSV file \n",
    "for archivo in archivos_csv:\n",
    "    ruta_completa = os.path.join(result_dir, archivo)\n",
    "    df = pd.read_csv(ruta_completa, sep=';', encoding='utf-16')\n",
    "    dataframes.append(df)\n",
    "    \n",
    "\n",
    "# Join all the files\n",
    "portadas = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Clean the data, take just the principal information...  \n",
    "# ... for each variable using regexFrontData function \n",
    "exportable = regexFrontData(portadas)\n",
    "print(len(exportable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(exportable, f'{monitoring_dir}/{fl_master}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
